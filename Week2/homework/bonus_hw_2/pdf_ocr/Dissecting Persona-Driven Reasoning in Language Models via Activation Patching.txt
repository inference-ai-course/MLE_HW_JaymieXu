arX1v:2507.20936v1 [cs.LG] 28 Jul 2025

Dissecting Persona-Driven Reasoning in Language Models
via Activation Patching

Ansh Poonia
pooniaansh11@gmail.com

Abstract

Large language models (LLMs) exhibit remark-
able versatility in adopting diverse personas. In
this study, we examine how assigning a per-
sona influences a model’s reasoning on an ob-
jective task. Using activation patching, we take
a first step toward understanding how key com-
ponents of the model encode persona-specific
information. Our findings reveal that the early
Multi-Layer Perceptron (MLP) layers attend
not only to the syntactic structure of the input
but also process its semantic content. These
layers transform persona tokens into richer rep-
resentations, which are then used by the middle
Multi-Head Attention (MHA) layers to shape
the model’s output. Additionally, we identify
specific attention heads that disproportionately
attend to racial and color-based identities.

1 Introduction

Recent advances in large language models (LLMs)
have demonstrated their striking ability to adopt a
wide range of personas, enabling context-sensitive
and tailored responses (Zhang et al., 2024, Joshi
et al., 2024, Sun et al., 2025). However, studies
such as those by Salewski et al., 2023, Deshpande
et al., 2023, Gupta et al., 2024, Zheng et al., 2024
show that persona assignment can significantly in-
fluence reasoning and, in some cases, amplify un-
derlying social biases. While these works focus
on identifying and quantifying such effects, they
do not examine the causal mechanisms within a
pre-trained language model (PLM) that give rise to
them. In this study, we take a step toward bridging
that gap by investigating the roles of key model
components—namely, the MLP layers, MHA lay-
ers, and individual attention heads—in shaping the
variation in reasoning induced by persona assign-
ments. Using activation patching, we probe the
internal circuitry of LLMs to trace the origins of
persona-driven variation in objective tasks. Our
findings challenge the prevailing assumption that

Maeghal Jain
maeghaljain@gmail.com

early MLP layers are concerned solely with syn-
tactic processing. We show that these layers also
encode semantic features related to persona. Fur-
thermore, we identify a small number of attention
heads that disproportionately focus on tokens as-
sociated with race-based persona cues. Although
our work is limited to uncovering the origin of
persona-driven behavior, it contributes to a deeper
understanding of LLMs and lays groundwork for
future efforts to mitigate deep-seated biases in these
systems.

2 Experimental Setup

2.1 Dataset Details

We chose the MMLU dataset (Hendrycks et al.,
2021) for this study, which contains 14,024
multiple-choice questions spanning 57 subjects.
We selected this dataset for two main reasons. First,
the objective, multiple-choice format allowed us to
focus on a fixed set of four answer tokens, giving
us a well-defined target. Second, the wide range
of subject areas helped reduce domain-specific or
persona-driven biases. The identities or personas
we examined in our study fall into four broad cate-
gories: racial identities, color-based identities, and
identities defined by positive or negative attributes;
details of each can be found in the Appendix A. To
maintain consistency and minimize variance, we
used "student" as a gender-neutral subject across
all defined identities. For instance: "Asian student",

mom

"white student", "good student", etc.

2.2 Model and Prompt

We use the LLaMA 3.2 1B Instruct model (Meta,
2024b) due to computational constraints. Its com-
pact size makes it well-suited for efficient exper-
imentation, while still delivering strong perfor-
mance relative to other open-source models in its
class. Our methods are scalable and can be ex-
tended to larger models with sufficient computa-

tional resources and minor adjustments. The In-
struct variant of the LLaMA family also permits
the use of system prompts!, allowing us to specify
the identity the model should adopt in its responses.
A standard system prompt serves as the base for
each question, enabling identity shifts by modi-
fying only two tokens in the entire prompt—just
one token distinguishes each identity. We used
the prompt structure defined by Meta for MMLU
dataset (Meta, 2024a), with the addition of the sys-
tem prompt, see Appendix B.

3 Persona Evaluation

We computed model outputs using zero-shot
prompts to isolate the variation introduced solely
by changes in the persona token, avoiding any influ-
ence from patterns introduced by few-shot prompt-
ing. This also reduced the length of each prompt, al-
lowing for faster computation. For each prompt, we
calculated the probability of the next token, which,
by design, corresponds to the selected answer for
the given question. This process was repeated for
all 16 identities, and also the base identity.

Our main focus is the change in the probability
of the correct token for each persona relative to the
base identity, as shown in Figure 1. This highlights
shifts in reasoning attributable to persona alone.
In some cases, the differences in probability fol-
lowed patterns that appeared to have a semantic ba-
sis. For instance, the negatively attributed student
persona performed significantly worse than those
described with positive attributes, having an aver-
age probability difference of -0.0045 (T = 14.36,
p < 0.001). In contrast, the results for racially or
color-coded personas were less consistent, and no
definitive conclusion could be drawn about whether
the patterns reflect stereotypical associations. A
similar trend was observed when examining accu-
racy across identities, see Appendix C for details.
Overall, our results suggest that the model’s rea-
soning ability varies even with minimal changes to
the persona being imitated.

4 Interpretability Investigation

4.1 Methods

We focus on activation patching, also referred to
as Resample Ablation, or Causal Mediation Analy-
sis (Vig et al., 2020, Meng et al., 2022), to under-

‘System prompts are instructions given to the AI before

any user input. They define the AI’s behavior, role, and re-
sponse style throughout an interaction.

good —LI+-—
bright rn ee ee
sharp CLR
intelligent ee
Asian I}
white +4
African -—_{_ IT}

2 Indian ee ee)

$ Brown a
stupid ——_ T+} +
Black {—_T >

Yellow +L}
British ——__E}+——+
dumb a
dull LE} c
bad -

-0.015  -0.010 = -0.005 0.000 0.005

Avg. Probability Difference

Figure 1: Average difference in the probability of the
correct token for each identity, relative to the base
prompt.

stand the influence of individual components on
the model’s selection of the correct answer. Specifi-
cally, we employ "de-noising" variant of activation
patching, where the activation of a component from
a corrupted run is replaced with the correspond-
ing activation from a clean run (Heimersheim and
Nanda, 2024). The clean and corrupted inputs are
constructed using Symmetric Token Replacement,
a technique in which only one or a few tokens
are altered (Meng et al., 2022, Wang et al., 2023).
This approach doesn’t throw the model’s internal
state out-of-distribution and preserves the syntactic
structure of the input (Zhang and Nanda, 2024).
For each experiment, we select a pair of personas
to generate the clean ([D/) and corrupted (ID2)
prompts. A total of ten persona pairs were chosen
keeping computational constraints in mind; details
are provided in the Appendix D. Care was taken to
balance pairings identities both within and across
categories to ensure reliable results. Pairings with
a base identity were also included for comparison.
For each pair, we divide the full set of questions
into four subsets, Appendix E. From these, we
select the subset in which the first persona (JD/)
answers correctly while the second persona ([D2)
answers incorrectly. In each such pair of prompts,
the only difference lies in the token representing
the persona. As a result, any change in the logit
of the correct answer after patching reflects the
influence of the component (and its downstream ef-
fects) on how the model processes persona-related
information.

4.2 Effects

The impact of patching on the model’s output can
be broken into direct and indirect effects (Pearl,

8

MLP Layers
8

10

6 15 14 «18° «12 «11

sé > ee #
Ro ‘ r rs a ea * & é
SSF KP EK SE SK S

> 100 os
Bs Average

MLP layer patching

10

oA

16 15 14 «13°«12:«11

02

04
Average

see oe ee?
FF oF FP FE OS

irons SF
ee rd

MHA layer patching

Figure 2: Relative logit difference (A,-) when MLP layer (left) and MHA layer (right) is patched. Accompanying

bar chart shows the average A,. across identity pairs.

2001). The direct effect measures the isolated con-
tribution of the component to the output. The in-
direct effect captures the influence the component
has via the behavior of later layers and is computed
by subtracting the direct effect from the total effect
of patching the component. Together, these effects
help characterize the role the component plays in
processing input information.

4.3 Metrics

To quantify the impact of patching, we use two met-
rics. First, we check whether patching causes the
logit (1) of the correct answer to become the highest
among all four options. Second, we measure the
relative logit difference (A,.), i.e., change in the
logit of the correct answer relative to the change in
the mean logit across all options.

A, = {leorrect (P) _ leorrect(C)}
— {u(lLason(P)) — w(lason(C))}

Here, |,.(P) is the logit from patched run and
1.(C) from corrupt run, and ju is mean function.
We use this relative metric rather than an abso-
lute one because some components may support
the correct answer not by increasing its logit di-
rectly, but by decreasing the logits of incorrect
options. An absolute measure—like simple logit
difference—would overlook such cases and only
highlight components with large magnitude effects

on the correct answer. These metrics are computed
across all selected questions for each persona pair.

4.4 Findings

We begin by patching the MLP and MHA layers
across all token positions. The Figure 2 shows A,
across all identity pairs, see Appendix F for results
on other metric. We observe that patching the early
MLP layers (layers 1-3) and the middle MHA lay-
ers (layers 9-11) produces a consistently higher
total effect across all ten identity pairs. We hypoth-
esize that the early MLP layers develop persona-
specific information, particularly at the token posi-
tion(s) representing the identity. This information
is then picked up and used by the later MHA layers,
giving rise to the observed persona-driven behav-
ior. To test this, we patch only the activations at the
identity token position in the MLP layers, rather
than all positions. We observed that patching ac-
tivations at the identity token position in the first
MLP layer produced an effect nearly equivalent to
patching all token positions. Beyond the first layer,
the effect rapidly decays, with later layers showing
little to no impact, see Appendix G.

We also find that only the MLP layers near the
end of the network have any direct effect on the
output, see Figure 3. This implies that the effect
seen in the initial layers is purely indirect. Since the
local syntax around the point of change remains
constant, this suggests that the initial MLP lay-

fro2
oz

123 4 5 6 7 8 9 10 11 12 13 14 15 16
MLP Layers

Figure 3: Average A, when only direct component of a
MLP layer is patched.

ers are processing not just structure but also the
semantics of the input tokens. This counter to ear-
ier findings (Belinkov et al., 2017, Peters et al.,
2018, Jawahar et al., 2019) that claimed these lay-
ers were focused only on syntactic or local features,
eaving semantic processing to later layers. The
subtlety of this semantic processing may explain
why it was overlooked in previous studies. Our re-
sults align with observations that initial MLP layers
transform tokens into richer representations (Stolfo
et al., 2023), supporting the hypothesis that these
ayers induce persona-specific semantics that later
ayers utilize.

To investigate MHA layer roles more closely,
we performed activation patching on individual
attention heads (H, end number) identifying eight
heads with a high positive effect on the output
and four with a high negative effect, see Figure 4.
We analyzed the value-weighted attention patterns
(Lieberum et al., 2023) of these heads on the iden-
tity token position across five questions per subject,
categorizing them based on the relative attention
given when compared with other identities, see
Appendix H. H3°, H?3, H?°, H}s, and Hi} con-
sistently allocated higher attention to tokens repre-
senting racial identities. H?°, H?;, and H}} also
showed elevated attention to color-based identi-
ties, though this pattern was less consistent across
domains. H}% uniquely focused on color-based
identities, while H?? prioritized both positive and
negative attributed identities at early token posi-
tions. We further examined how these attention
patterns of these heads responded to MLP layer
patching. When activations from runs with racial
or color-based personas were replaced with those
from positive or negative attributed personas, the at-
tention of heads previously showing high focus on
the identity token position decreased significantly.
This reduction occurred regardless of whether all
token positions or only the identity token position
were patched. For most heads, patching layers
beyond the first had minimal impact on attention
patterns, for details see Appendix I.

Our findings validate the hypothesis of an inter-

& i | 0.0
= |
F3
B10 a
ci i | IL:
” a a
8 a |
15 |

1.2.3 4 5 6 7 B 910111243 14151617 18 19 20.21 22 29.26 25 26 27 28 29.30 31 92
Aitention Heads

Figure 4: Average A, for patching individual attention
heads.

action between the initial MLP layers and the mid-
dle MHA layers in driving persona-driven behavior.
The initial MLP layers—especially at the identity
token position—form rich, persona-specific seman-
tic representations. These are then taken up by the
middle MHA layers, impacting the model’s choice
of response.

5 Discussion

In this work, we analyzed the impact of persona-
driven behavior on the reasoning ability of a lan-
guage model in objective tasks. Through the lens
of mechanistic interpretability, we examined the
role of different model components—MLLP layers,
MHA layers, and individual attention heads—in
shaping this behavior. We observed that early
MLP layers also contributes towards semantic un-
derstanding of inputs and encode persona-specific
information into richer representation. This infor-
mation is then passed to later MHA layers, which
use it to influence the model’s response. We further
categorized attention heads based on their relative
attention patterns and identified a subset that as-
signed disproportionate weight to racial and color-
related attributes associated with a persona.

Our findings offer preliminary insight into the
subtle yet significant functions of certain model
components and how they can be revealed through
constrained but straightforward experiments. We
took initial steps toward understanding the origins
of persona-driven behavior in LLMs. In future
studies, we will investigate why certain personas
answer specific questions correctly while others do
not, and how output vector circuits in attention
heads use earlier-layer representations to shape
final predictions. These directions will lead to
a deeper understanding of what "persona" truly
means in the context of language models.

Limitations

Although the MMLU dataset contains a large num-
ber of mostly factual, objective questions, we ac-
knowledge that it is not the only dataset that meets
our selection criteria. Our experiments were con-
ducted exclusively on the LLaMA 3.2 1B Instruct
model, due to computational and time constraints.
However, the methods described here can be read-
ily extended to models of different sizes and archi-
tectures, as well as to other datasets with similar
characteristics.

We selected a set of 16 personas to approximate
the space relevant to our probing efforts. The list
of personas is not exhaustive, but it serves as a
practical starting point. Our analysis focused on
attention heads identified as important through ac-
tivation patching. Examining additional heads may
improve our understanding of how persona-driven
behavior develops within the model. At present,
however, attention pattern analysis requires man-
ual inspection, which remains a slow and labor-
intensive process.

References

Yonatan Belinkov, Lluis Marquez, Hassan Sajjad, Nadir
Durrani, Fahim Dalvi, and James Glass. 2017. Evalu-
ating layers of representation in neural machine trans-
lation on part-of-speech and semantic tagging tasks.
In Proceedings of the Eighth International Joint Con-
ference on Natural Language Processing (Volume
1: Long Papers), pages 1-10, Taipei, Taiwan. Asian
Federation of Natural Language Processing.

Ameet Deshpande, Vishvak Murahari, Tanmay Rajpuro-
hit, Ashwin Kalyan, and Karthik Narasimhan. 2023.
Toxicity in chatgpt: Analyzing persona-assigned lan-
guage models. In Findings of the Association for
Computational Linguistics: EMNLP 2023, pages
1236-1270, Singapore. Association for Computa-
tional Linguistics.

Shashank Gupta, Vaishnavi Shrivastava, Ameet Desh-
pande, Ashwin Kalyan, Peter Clark, Ashish Sabhar-
wal, and Tushar Khot. 2024. Bias runs deep: Implicit
reasoning biases in persona-assigned LLMs. In The
Twelfth International Conference on Learning Repre-
sentations.

Stefan Heimersheim and Neel Nanda. 2024. How to

use and interpret activation patching. arXiv preprint
arXiv:2404.15255.

Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou,
Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
2021. Measuring massive multitask language under-
standing. In International Conference on Learning
Representations.

Ganesh Jawahar, Benoit Sagot, and Djamé Seddah.
2019. What does BERT learn about the structure of
language? In Proceedings of the 57th Annual Meet-
ing of the Association for Computational Linguistics,
pages 3651-3657, Florence, Italy. Association for
Computational Linguistics.

Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung
Kim, and He He. 2024. Personas as a way to model
truthfulness in language models. In Proceedings of
the 2024 Conference on Empirical Methods in Natu-
ral Language Processing, pages 6346-6359, Miami,
Florida, USA. Association for Computational Lin-
guistics.

Tom Lieberum, Matthew Rahtz, Janos Kramar, Neel
Nanda, Geoffrey Irving, Rohin Shah, and Vladimir
Mikulik. 2023. Does circuit analysis interpretability
scale? evidence from multiple choice capabilities in
chinchilla. arXiv preprint arXiv:2307.09458.

Kevin Meng, David Bau, Alex J Andonian, and Yonatan
Belinkov. 2022. Locating and editing factual associ-
ations in GPT. In Advances in Neural Information
Processing Systems.

Meta. 2024a. Llama 3.2 Evals.
Meta. 2024b. Llama 3.2 family of models.

Judea Pearl. 2001. Direct and indirect effects. In
Proceedings of the Seventeenth Conference on Un-
certainty in Artificial Intelligence, UAV01, page
411-420. Morgan Kaufmann Publishers Inc.

Matthew E. Peters, Mark Neumann, Luke Zettlemoyer,
and Wen-tau Yih. 2018. Dissecting contextual word
embeddings: Architecture and representation. In Pro-
ceedings of the 2018 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1499-
1509, Brussels, Belgium. Association for Computa-
tional Linguistics.

Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto,
Eric Schulz, and Zeynep Akata. 2023. In-context im-
personation reveals large language models’ strengths
and biases. In Thirty-seventh Conference on Neural
Information Processing Systems.

Alessandro Stolfo, Yonatan Belinkov, and Mrinmaya
Sachan. 2023. A mechanistic interpretation of arith-
metic reasoning in language models using causal
mediation analysis. In Proceedings of the 2023 Con-
ference on Empirical Methods in Natural Language
Processing, pages 7035-7052, Singapore. Associa-
tion for Computational Linguistics.

Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi Fung,
Hou Pong Chan, Kevin Small, ChengXiang Zhai,
and Heng Ji. 2025. Persona-DB: Efficient large lan-
guage model personalization for response prediction
with collaborative data refinement. In Proceedings
of the 31st International Conference on Computa-
tional Linguistics, pages 281-296, Abu Dhabi, UAE.
Association for Computational Linguistics.

Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov,
Sharon Qian, Daniel Nevo, Yaron Singer, and Stu-
art Shieber. 2020. Investigating gender bias in lan-
guage models using causal mediation analysis. In
Advances in Neural Information Processing Systems,
volume 33, pages 12388-12401. Curran Associates,
Inc.

Kevin Ro Wang, Alexandre Variengien, Arthur Conmy,
Buck Shlegeris, and Jacob Steinhardt. 2023. Inter-
pretability in the wild: a circuit for indirect object
identification in GPT-2 small. In The Eleventh Inter-
national Conference on Learning Representations.

Fred Zhang and Neel Nanda. 2024. Towards best prac-
tices of activation patching in language models: Met-
rics and methods. In The Twelfth International Con-
ference on Learning Representations.

Zhehao Zhang, Ryan A Rossi, Branislav Kveton, Yijia
Shao, Diyi Yang, Hamed Zamani, Franck Dernon-
court, Joe Barrow, Tong Yu, Sungchul Kim, and 1
others. 2024. Personalization of large language mod-
els: A survey. arXiv preprint arXiv:2411.00027.

Minggqian Zheng, Jiaxin Pei, Lajanugen Logeswaran,
Moontae Lee, and David Jurgens. 2024. When ”a
helpful assistant” is not really helpful: Personas in
system prompts do not improve performances of
large language models. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2024,
pages 15126-15154, Miami, Florida, USA. Associa-
tion for Computational Linguistics.

A Identities

In this study, personas—or identities—refer to sin-
gle words such as "Asian" or "good." The selected
identities fall into four broad categories, with four
identities chosen from each to ensure balanced com-
parisons. A further criterion in selection was that
each identity should be of a single token, so that
the only variation between prompts would be one
token. Table 1 lists the identities alongside their
respective categories.

B_ Prompt Structure

The prompt format used throughout the study is
shown in Figure 5. The placeholder {helper} is
replaced with "a" or "an" depending on whether
the first letter of {identity_1} is a vowel. The
variable {identity_1} is substituted with the iden-
tities listed in Table 1, or with "helpful" in the
base prompt. The placeholder {identity_2} is
replaced with "student" in the persona prompts
and with "assistant" in the base prompt. The
{question} field is filled with the target question,
and each {option_*} is replaced by the corre-
sponding answer choice.

Table 1: Identities with their respective category.

Category

Identity

Racial-based

Asian
Indian
African
British

Color-based

White
Black
Brown
Yellow

Positive-attributes

good
intelligent
bright
sharp

Negative-attributes bad

dull
stupid
dumb

ID1

ID2

Asian student
helpful assistant
Asian student
White student
good student
Indian student
good student
African student
helpful assistant
dumb student

Indian student
Asian student
Yellow student
Black student
bad student
Brown student
sharp student
British student
White student
bad student

Table 2: Identity Pairs

<|begin_of_text|><|start_header_id|>

system<|end_header_id|> You are {helper}
{identity_1} {identity_2}.<|eot_id|>
<|start_header_id|>user<|end_header_id|>
Given the following question and four
candidate answers (A, B, C and D), choose
the best answer.

Question: {question}

{option_1}
{option_2}
{option_3}
{option_4}

VTAwWE

Your response should end with "The best
answer is [the_answer_letter]" where

the [the_answer_letter] is one of

A, B, C or D.<|eot_id|><|start_header_id|>
assistant<|end_header_id|>

The best answer is

Figure 5: MMLU prompt structure.


bad H

bright ——_L +
good +

intelligent +
sharp —L I+
Yellow on a

African
Brown

Identity

dull
Indian
dumb
stupid
Asian
British
White
Black

- 0 2
‘Avg. Accuracy Difference (%)

Figure 6: Difference in accuracy of identities w.r.t. base.

Baseline holpful

‘good
bright
Positive
sharp

intotigent

0.008
Asian
ican 0.00
Race
Indian
Bitish 0.000
wite
Brown eve
color
Bik
Yetow eos
stupid
.
Negative
cut
ws mn
SP SLES S SSOP SOLOS
PES I FFE FE EEE ESE FF

Figure 7: Average difference in probability of correct
token of identities w.r.t. each-other.

C_ Additional Performance Results

Figure 6 shows the accuracy for each identity, rel-
ative to the base. Average across the subjects of
difference in probability of correct token for a given
identity relative to other identities is shown in Fig-
ure 7.

D Identity Pairs

Table 2 shows the selected identity pairs. During
activation patching, the prompt for ID1 serves as
the clean prompt, while the prompt for ID2 serves
as the corrupt prompt. Activations from the ID2
run are replaced with those from the ID1 run to
identify which components restore the model’s out-
put to that of ID1. The only difference between the
ID1 and ID2 prompts is the identity token—except
when ID1 corresponds to the base prompt, in which
case "assistant" is replaced with "student."

Identity pair cl c2 C3 C4
Asian, Indian | 6909 6820 164 149
helpful, Asian | 6846 6707 262 227
Asian, Yellow | 6888 6771 185 198
White, Black | 6866 6831 188 157
good, bad 6834 6691 272 245
Indian, Brown | 6855 6781 203 203
good, sharp 7035 6864 71 72
African, British | 6863 6787 197 195
helpful, White | 6808 6688 300 246
dumb, bad 6824 6726 237 255

Table 3: Number of questions in each subset

E Question Subsets

For each identity pair (ID1, ID2), the questions
in the dataset are divided into four subsets: $1 —
questions answered correctly by both identities;
S2 — questions answered incorrectly by both; $3 —
questions answered correctly by ID1 but incorrectly
by ID2; S4 — questions answered correctly by ID2
but incorrectly by ID1. The number of questions
in each category for the selected identity pairs is
shown in Table 3.

Questions from subset $3 were chosen for acti-
vation patching because they offer a well-defined
target token to observe during the patched run. In
the ID2(corrupt) run, the logit of the correct to-
ken is lower than in the ID1(clean) run. Therefore,
components that raise the logit of the correct token
during the patched run help restore the model’s
behavior to that of ID1.

F Additional Patching Results

We also measured, for each identity pair (1D1,
ID2), the proportion of questions where ID1 an-
swered correctly and ID2 did not, such that patch-
ing the activation of an MLP or MHA layer from
ID1’s run into ID2’s run caused the correct token
to receive the highest logit. Figure 8 presents the
results for both MLP and MHA layers, as well as
their average across all identity pairs.

G_Identity-token-position Patching
Results

The relative change in the logit of the correct token,
when only the identity token position’s activation
is patched for the MLP layer, is shown in Figure 9.
Figure 10 shows the percentage of questions for
which the correct token receives the highest logit.

MHA Layers
10

"

413
413 12

18

6

* o 0 6
; Se ” ce ma - af ra ‘Average %
vee s & ¢ & Ss ee
MLP layer patching

&

ss
at

»

00

ee ee

se

MHA layer patching

Figure 8: Percentage of questions whose logit of correct token became maximum after patching MLP layer (left)

and MHA layer (right).

~ a
° | ie
*
©
©
on I
ge
-0.0
ao
=e i
PS 0.2
ay
2
x
2
2
S € SS fF RY Ss 2
FFF FF F&C
SS SS S ee se Ss
i ar ir

@
Ea
&
@
Ss
a
Ss
=

a
©
+
©
©
S
©
o
2
a
2
2
2
2

100

50

& SS & $
ar ro
se &
BS
ef &

Figure 9: Relative logit difference (A,-) when only ac- _ Figure 10: Percentage of questions whose logit of cor-

tivation at identity token position is patched for MLP

rect token became maximum after patching activation

layers. at identity token position for MLP layer.

H_ Attention Visualization

Attention heads were selected based on high posi-
tive effect (H2°, H25, H?), H28, H27, H®,, H}4,
H?2), and high negative effect (H{i, H},, H}S,
H?8). Figure 11 shows the relative value-weighted
attention given at the identity token position by
selected attention heads, for a sample question
from the dataset. Relative value-weighted atten-
tion is computed by subtracting the mean value-
weighted attention across all identities from the
value-weighted attention assigned to a given iden-
tity. This highlights the heads that pay dispropor-
tionately more attention to a specific identity or
group of identities.

I Attention after patching

Figure 12 shows the change in value-weighted at-
tention at the identity position when MLP layer
activations are patched from the "good" run into
the "Asian" run for a given question. The results
indicate that racial heads (attention heads that al-
located higher attention to racial-based identity to-
kens) assigns significantly less attention when the
activations of early MLP layers are patched.

Pa)
N

3

S

o

x=

o ~ Mo}

a 112A
a - uMolg
i eld

g

>

i

4

~uelsy
- Injdjay

~ MO}|2A,
-umoug
>peid

Layer: 10; Head: 25

ra
a

»

Es

ES)

= ~ MOIL2A
a - umosg
5 >peid

S

i}

Ss

-uelsy

Layer: 12; Head: 9

|
|
r
qi
8 |
z
a fl |
dj
g
®
§
|
I
©
Ss
S
s |
z= i
dj
g
= Vin |

ra
a

a
3

48 -

+2
a

©
8
|SOd

uaxoL,

-ueisy
= Injdjay

-ueryy
~ ueipuy
-ueisy

- Injdjay

Layer: 13; Head: 3 Layer: 13; Head: 14

Layer: 12; Head: 11

-pidms
-quinp
~peq

- dueys
~346uq

- yuabyy/2qU!
- poob

~ MO}|2A,
-umoug
>peid

-pidms
~quinp
~peq

~1Inp
- dieys

- 346g

- yuabyy/2qU!
- poob

~ MO]|2A,

- umoug
>peig

-pidms
-quinp
~peq

- dieys
~346uq

- yuabyy/2qU!
- poob

~ MO}|2A,
-umoug
>peid

-us
- ued

Layer: 15; Head: 26

-ueisy
-Injdjay
©

- pidmys

~quinp
~peq
~1Inp
- dueys
| ~ay6uq
~ queby equ!
| = poob

Layer: 15; Hea:

©

2

3

Es

ES}

x

=

ba

o

S

EG)

Ss
-uer1yy
~ ueipuy
-ueisy
= Inydjay

. The

token position.

ity

heads at identi

Jon

by selected attenti

1on given

hted attent

ive value-weig!

Relat
prompt used is the first question from "Abstract Algebra" subject.

Figure 11

10

- yaied 9T-d1W
~ypqed ST-d1W
~ypqed pT-d1W
-ypqed €T-c1W
~ypqed Z1-d1W
~ypied TT-d1W
- ysqed OT-d1W
- yaied 6-c1W
- yaied 8-c1W
- yaied £-c1W
- yaied 9-c1W
- yaied S-c1W
- yaied y-a1W
- yaied €-c1W
- yaied Z-c1W
- ypied T-c1W
~ und ueisy,

~ uns ,poob,

Layer: 11; Head: 25

- yaied 9T-c1W.
- yied sT-c1W,
- yied pT-c1W.
~yaied €T-c1W,
- yaied Z1-c1W.
- yaied TT-c1W.
- yaied OT-c1W.
- yred 6-aW
- yaied e-aW
- yard -aW

| - ued o-aw
-yaed ¢-aW
- yied paw
- yard €-aW
- yaied Z-aW
-yned Taw
- ung ,ueisy,

~ uns ,p006,

Layer: 10; Hea

- yoied 9T-cIW.
-yoied ST-cIW.
-yied pT-cIW
-yoied €T-cIW
-yied ZT-c1W
-yied T-aW
- yoied OT-cIW
- yned 6-c1W
- yoed 8-c1W.
-yoed L-c1W
- yoied 9-c1W.
- yoed S-c1W.
- yned b-c1W.
- yned €-c1W.
- yoed 2-c1W.
- yd T-c1W
- und ,ueisy,

- und ,poob,

-yoqed 9T-d1W
-yoqed ST-d1W
-yoied pl-d1W
-yoqed €L-d1W
-yoqed Z1-d1W
-yoqed TL-d1W
-yoqed O1-d1W
| -yoied 6-d1W
-yoqed 8-d1W
-yoqed /-d1W
-yoqed 9-d1W
-yoied S-d1W
-yoied p-dIW
-yoqed €-d1W

Layer: 12; Head: 9

-yoqed T-d1W
~ uns ,ueisy,
- uns ,poob,

- yoied 9T-d1W
- yaied ST-d1W
-yaied pT-d IW
-ypied €T-d1W
-ypied ZT-d1W
- yoaed TT-d1W
- yozed OT-d1W
| -ypied 6-d1W
-ypied 8-1,
| -ypied L-41W,
-ypied 9-41W,
-ypied S-41W,
| -ypied p41,
| -ypied €-41W
-ypied 2-41,
-ynied TW
- uns ueisy,
- uns ,poob,

Layer: 11; Head: 27

-yoqed 9T-d1W
-yoqed ST-d1W
-yoied pl-d1W
-yoqed €T-d1W
-yoqed Z1-d1W
-yoqed TL-d1W
-yoqed OT-d1W
-yoied 6-d1W
-yoqed 8-d1W
-yoqed /-d1W
-yoied 9-d1W
-yoied S-d1W
-yoied p-dIW
| ~ynied €-41W,
-yoqed 7-d1W
| -ypied T-41W
- und uelsy,
- uns ,poob,

Layer: 11; Head: 26

- wied 9T-d1W
~ upqed ST-d1W
- uied pT-d1W
- uqed €T-d TW
- uqed 2T-d1W
- uqed TT-d1W
- upqed OT-d1W
-wied 6-41,
- wied 8-41
-wied 1-41
- wied 9-41
-wied $41
-wied 41
1 - pied €-d1W
-wied 7-41,
-wied TW
- uns jueisy,
~ uns ,poob,

Layer: 13; Head: 14

sUO!ySOdg UDO)

- ypied 9T-d1W
- pied ST-d1W
- pied pT-d1W
-ypjed €T-d1W
- pied Z-d1W
-ypied TI-d1W
- pied OL-d1W
I - pied 6-d1W
-ypqed 8-d1W
-ypqed /-d1W
-yoqed 9-d1W
-ypqed S-d1W
-ypqed p-d1W
-upqed €-d1W
-ypqed Z7-d1W
I - ypied T-d1W
- uns ,ueisy,

Layer: 13; Head: 3

sUO!ySOdg UDO)

- pied 9T-d1W
- pied ST-d1W
- pied pT-d1W
~ypied €T-d1W
- pied Z-d1W

I ~ pied T-d1W
- ypied OL-d1W
-ypqed 6-d1W
-ypqed 8-d1W
-ypqed /-d1W
= ypqed 9-d1W
-ypqed S-d1W

i -ypqed p-d1W
- ypqed €-d1W
-ypqed Z7-d1W

| - ypied T-d1W
~ uns ,ueisy,

~ uns ,poob,

Layer: 12; Head: 11

sUO!ySOdg UDO)

-yored 9T-d1W
-yored ST-d1W
-yed pl-d1W
-yied €L-d1W
-yred Z1-d1W
-yored TL-d1W
-yored O1-d1W
-yaqed 6-d1W
-yoqed 8-d1W
-yoqed /-d1W
| -yaqed 9-d1W
-yoqed ¢-d1Ww
-ynied p-d1W
-yoied €-d1W
-yoied 7-d1W
I - pied T-d1W
-uns wueisy,
uns ,poob,

Layer: 15; Head: 26

-yored 9T-d1W
-yored ST-d1W
-yed pl-d1W
-yied €1-d1W
-yred Z1-d1W
-yoed TL-d1W
-yored OL-d1W
-yoied 6-d1W
-yoied 8-d1W
-yoqed £-d1W
-yoqed 9-d1W
-yoqed S-d1W
-yied p-d1W
-yoied €-d1W
-yoied Z-d1W
-yored T-d1W
-uns ,ueisy,

~ uns ,poo6,

Layer: 15; Head: 25

| ~ypqed 9T-d1W
-yaied ST-d1W
-ypied pT-d1W
~ypied €T-d1W
-yaied ZT-d1W
-yaied TI-d1W
| ~upied OT-d1W
-ynied 6-41W
-ynied 8-1W,
-yied L-41W,
-ynied 9-41,
-ynied S-41W,
-ynied b-d1W.
-ynied €-41W
-ynied 2-41,
-ynied TW
- uns ueisy,
- uns ,p006,

Layer: 13; Head: 16

ing

ken position after patch:
is the first question from "Abstract Algebra

ity tol

by selected heads at ident

1on given

hted attenti

activation at identity token position for MLP layer. The prompt used

subject.

-weig|

Figure 12: Relative value

11

